{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-29T02:24:57.297491Z","iopub.execute_input":"2023-06-29T02:24:57.298236Z","iopub.status.idle":"2023-06-29T02:25:10.472771Z","shell.execute_reply.started":"2023-06-29T02:24:57.298197Z","shell.execute_reply":"2023-06-29T02:25:10.471228Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 1. Introduction + Set-up\n\nMachine learning has a phenomenal range of applications, including in health and diagnostics. This tutorial will explain the complete pipeline from loading data to predicting results, and it will explain how to build an X-ray image classification model from scratch to predict whether an X-ray scan shows presence of pneumonia. This is especially useful during these current times as COVID-19 is known to cause pneumonia.\n\nThis tutorial will explain how to utilize TPUs efficiently, load in image data, build and train a convolution neural network, finetune and regularize the model, and predict results. Data augmentation is not included in the model because X-ray scans are only taken in a specific orientation, and variations such as flips and rotations will not exist in real X-ray images. For a tutorial on image data augmentation, check out this [tutorial](https://www.kaggle.com/amyjang/tensorflow-data-augmentation-efficientnet).\n\nRun the following cell to load the necessary packages. Make sure to change the Accelerator on the right to `TPU`.","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-06-29T02:25:27.286018Z","iopub.execute_input":"2023-06-29T02:25:27.286523Z","iopub.status.idle":"2023-06-29T02:25:38.150810Z","shell.execute_reply.started":"2023-06-29T02:25:27.286488Z","shell.execute_reply":"2023-06-29T02:25:38.149798Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Number of replicas: 1\n2.12.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We need a Google Cloud link to our data to load the data using a TPU. While we're at it, we instantiate constant variables. It is generally better practice to use constant variables instead of hard-coding numbers.","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [180, 180]\nEPOCHS = 25","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Load the data\n\nThe Chest X-ray data we are using from [*Cell*](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) divides the data into train, val, and test files. There are only 16 files in the validation folder, and we would prefer to have a less extreme division between the training and the validation set. We will append the validation files and create a new split that resembes the standard 80:20 division instead.","metadata":{}},{"cell_type":"code","source":"filenames = tf.io.gfile.glob(str(GCS_PATH + '/chest_xray/train/*/*'))\nfilenames.extend(tf.io.gfile.glob(str(GCS_PATH + '/chest_xray/val/*/*')))\n\ntrain_filenames, val_filenames = train_test_split(filenames, test_size=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run the following cell to see how many healthy/normal chest X-rays we have and how many pneumonia chest X-rays we have.","metadata":{}},{"cell_type":"code","source":"COUNT_NORMAL = len([filename for filename in train_filenames if \"NORMAL\" in filename])\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n\nCOUNT_PNEUMONIA = len([filename for filename in train_filenames if \"PNEUMONIA\" in filename])\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice that the there are way more images that are classified as pneumonia than normal. This shows that we have a imbalance in our data. We will correct for this imbalance later on in our notebook.","metadata":{}},{"cell_type":"code","source":"train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n\nfor f in train_list_ds.take(5):\n    print(f.numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run the following cell to see how many images we have in our training dataset and how many images we have in our validation set. Verify that the ratio of images is 80:20.","metadata":{}},{"cell_type":"code","source":"TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, we have two labels for our images.","metadata":{}},{"cell_type":"code","source":"CLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n                        for item in tf.io.gfile.glob(str(GCS_PATH + \"/chest_xray/train/*\"))])\nCLASS_NAMES","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Currently our dataset is just a list of filenames. We want to map each filename to the corresponding (image, label) pair. The following methods will help us do that.\n\nAs we only have two labels, we will rewrite the label so that `1` or `True` indicates pneumonia and `0` or `False` indicates normal.","metadata":{}},{"cell_type":"code","source":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == \"PNEUMONIA\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The images originally have values that range from [0, 255]. CNNs work better with smaller numbers so we will scale this down.","metadata":{}},{"cell_type":"code","source":"def decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels=3)\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n  return tf.image.resize(img, IMAGE_SIZE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\nval_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the shape of an (image, label) pair.","metadata":{}},{"cell_type":"code","source":"test_list_ds = tf.data.Dataset.list_files(str(GCS_PATH + '/chest_xray/test/*/*'))\nTEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\ntest_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n\nTEST_IMAGE_COUNT","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Visualize the dataset\n\nFirst, let's use buffered prefetching so we can yield data from disk without having I/O become blocking.","metadata":{}},{"cell_type":"code","source":"def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    ds = ds.repeat()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Call the next batch iteration of the training data.","metadata":{}},{"cell_type":"code","source":"train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\n\nimage_batch, label_batch = next(iter(train_ds))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the method to show the images in the batch.","metadata":{}},{"cell_type":"code","source":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(25):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the method takes in numpy arrays as its parameters, call the numpy function on the batches to return the tensor in numpy array form.","metadata":{}},{"cell_type":"code","source":"show_batch(image_batch.numpy(), label_batch.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-06-29T02:29:08.892725Z","iopub.execute_input":"2023-06-29T02:29:08.893071Z","iopub.status.idle":"2023-06-29T02:29:08.909125Z","shell.execute_reply.started":"2023-06-29T02:29:08.893043Z","shell.execute_reply":"2023-06-29T02:29:08.907931Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    As the method takes in numpy arrays as its parameters, call the numpy function on the batches to return the tensor in numpy array form.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3302885333.py, line 1)","output_type":"error"}]},{"cell_type":"markdown","source":"# 4. Build the CNN","metadata":{}},{"cell_type":"code","source":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    \n    return block","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Correct for data imbalance","metadata":{}},{"cell_type":"code","source":"initial_bias = np.log([COUNT_PNEUMONIA/COUNT_NORMAL])\ninitial_bias","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_for_0 = (1 / COUNT_NORMAL)*(TRAIN_IMG_COUNT)/2.0 \nweight_for_1 = (1 / COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Train the model","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n    \n    model.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=METRICS\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n    class_weight=class_weight,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Finetune the model","metadata":{}},{"cell_type":"code","source":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n                                                     restore_best_weights=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch / s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n    epochs=100,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler]\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Visualizing model performance\n","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Predict and evaluate results","metadata":{}},{"cell_type":"code","source":"loss, acc, prec, rec = model.evaluate(test_ds)","metadata":{},"execution_count":null,"outputs":[]}]}